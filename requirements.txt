import requests
from bs4 import BeautifulSoup

# Make a GET request to a website
response = requests.get('https://www.example.com')

# Check if the request was successful
if response.status_code == 200:
    # Parse the HTML content of the response
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all the links on the page
    links = soup.find_all('a')

    # Print the URLs of the links
    for link in links:
        print(link.get('href'))
else:
    print('Failed to retrieve website content')
